{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray is the input frame converted into gray scale for the facial recognition \n",
    "#frame is returned with rectangles drawn if faces were found\n",
    "def detect(gray, frame):\n",
    "\n",
    "    #we require that there must be 5 neighboring accepted features to be classified true\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces : \n",
    "        #top left coordinates, bottom right coordinates, red, 2 thickness\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        #region of interest to detect the eyes \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        #1.1 is the zoom from the original given image \"roi_gray\"\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "        \n",
    "        #finding the eyes within the already classified face images to save compute power\n",
    "        for (ex, ey, ew, eh) in eyes : \n",
    "            print(ex, ey)\n",
    "            #top left coordinates, bottom right coordinates, green, 2 thickness\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.7, 22)\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 0, 255), 2)\n",
    "    return frame\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 117\n",
      "188 84\n",
      "83 118\n",
      "211 104\n",
      "62 96\n",
      "216 109\n",
      "82 112\n",
      "199 87\n",
      "57 90\n",
      "208 78\n",
      "213 98\n",
      "76 105\n",
      "60 106\n",
      "212 101\n",
      "72 108\n",
      "158 292\n",
      "78 110\n",
      "211 100\n",
      "204 95\n",
      "68 101\n",
      "174 187\n",
      "159 202\n",
      "220 103\n",
      "93 118\n",
      "68 96\n",
      "204 95\n",
      "66 104\n",
      "198 93\n",
      "64 103\n",
      "223 115\n",
      "87 124\n",
      "184 91\n",
      "222 113\n",
      "81 118\n",
      "77 118\n",
      "218 111\n",
      "211 116\n",
      "72 117\n",
      "190 93\n",
      "205 106\n",
      "59 109\n",
      "228 124\n",
      "215 109\n",
      "207 101\n",
      "306 47\n",
      "256 131\n",
      "228 108\n",
      "232 122\n",
      "230 123\n",
      "230 120\n",
      "222 102\n",
      "229 109\n",
      "210 99\n",
      "225 129\n",
      "186 83\n",
      "207 102\n",
      "207 106\n",
      "246 120\n",
      "206 101\n",
      "238 130\n",
      "239 134\n",
      "209 106\n",
      "208 254\n",
      "234 129\n",
      "244 132\n",
      "222 119\n",
      "209 111\n",
      "190 240\n",
      "190 88\n",
      "189 92\n",
      "176 224\n",
      "177 195\n",
      "185 84\n",
      "196 102\n",
      "219 126\n",
      "203 254\n",
      "215 115\n",
      "219 119\n",
      "208 252\n",
      "233 131\n",
      "218 127\n",
      "297 66\n",
      "222 127\n",
      "217 125\n",
      "224 126\n",
      "211 122\n",
      "204 108\n",
      "218 118\n",
      "209 110\n",
      "251 124\n",
      "212 107\n"
     ]
    }
   ],
   "source": [
    "while True : \n",
    "    _, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
